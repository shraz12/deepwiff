{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Beta_Distribution_Network.ipynb","provenance":[{"file_id":"1SY1C-mk7kaMT7OJ58TN5YweHFL2iVU6i","timestamp":1607677500047},{"file_id":"1PAU0JdrtTFrbYBq6zL2z-36N6-St_0lm","timestamp":1607117522414},{"file_id":"1AB4ogjK3lQveiLvbqUYONuacLWlwoKFV","timestamp":1606786393510}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"fp0rwy5rGb7-"},"source":["'''\n","Beta distribution neural network with 4 hidden dense layers \n","and 2 beta distribution parameter layers to predict output distribution.\n","Preprocessing code written by Prof. Horvat, network code written by Meal Swipes for Late Days.\n","Input is a (batch_size x 26) tensor representing the input wave spectrum, \n","output is a (batch size x 49) tensor representing the output floe size distribution.\n","'''\n","import os\n","os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from scipy.io import loadmat,savemat\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow_probability as tfp\n","import random\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.callbacks import EarlyStopping\n","from google.colab import drive "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWTcM43_Gb8A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607679917501,"user_tz":300,"elapsed":59115,"user":{"displayName":"Jacob DiChiacchio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggsml0EbzAAuAM2dlM7pejj_NgNEY5eL2kWsPwm=s64","userId":"01066648639217777069"}},"outputId":"27dbe9bf-abbd-4d7e-da03-34c246a6402b"},"source":["# Define file locations\n","\n","usable_class = 0\n","\n","include_last = True;\n","\n","drive.mount('/content/drive', force_remount=True)\n","# locstr = '/Users/chorvat/Dropbox (Brown)/Research Projects/Active/FSTD-Ongoing-Work/Neural-Net-Waves/'\n","locstr = '/content/drive/Shared drives/DeepWIFF/'\n","\n","training_string = locstr + 'Data/training_data_errtol'\n","\n","if not include_last:\n","    training_string = training_string + '_nolast'\n","\n","training_string = training_string + '.mat'\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLcBHshGGb8A","executionInfo":{"status":"ok","timestamp":1607679930057,"user_tz":300,"elapsed":16317,"user":{"displayName":"Jacob DiChiacchio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggsml0EbzAAuAM2dlM7pejj_NgNEY5eL2kWsPwm=s64","userId":"01066648639217777069"}},"outputId":"782b0da0-b6cb-447a-c7b7-51c7f9b6d6aa"},"source":["'''\n","Loads training data and performs preprocessing to remove degenerate inputs.\n","There is no need to run this cell once the pickle files have been saved once.\n","'''\n","\n","training_data = loadmat(training_string)\n","misc_data = loadmat(locstr + 'Data/NN_params.mat')\n","\n","input_vec = training_data['input_vec'].T\n","output_vec = training_data['output_vec'].T\n","\n","Freq = misc_data['f']\n","dFreq = Freq * (np.sqrt(1.1) - np.sqrt(1/1.1)); \n","Redge = misc_data['redge'].T\n","Rcent = misc_data['rcent'].T\n","Lambda = misc_data['lambda']\n","\n","\n","num_frac = np.sum(output_vec,axis=1)\n","# classifier = load_model('Classifiers/KERAS-Classifier-25x25.h5')\n","# thresh = 0.11;\n","# y_pred_class = classifier.predict(input_vec)\n","# usable = y_pred_class[:,1] > thresh\n","\n","usable = num_frac > 0\n","print('Out of ' + str(len(num_frac)) + ', ' + str(sum(usable)) + ' can be used')\n","\n","ice_thick = input_vec[:,-1]\n","wave_spec = input_vec[:,:25]\n","\n","# wave_spec[wave_spec < 10**-8] = 0\n","wave_energy = np.sum(wave_spec*np.expand_dims(dFreq,axis=1).T,axis=1)\n","peak_loc = np.argmax(wave_spec,axis=1)\n","peak_freq = Freq[peak_loc]\n","\n","NN_input = input_vec[usable]\n","NN_output = output_vec[usable]\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Out of 1830900, 404503 can be used\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z8I8k03NGb8A"},"source":["'''\n","Loads training and testing data from pickle file.\n","'''\n","import pickle\n","\n","try:\n","\n","    X_train = pickle.load( open(locstr +  \"Data/\" + \"X_train.p\", \"rb\" ) )\n","    X_test = pickle.load( open( locstr + \"Data/\" + \"X_test.p\", \"rb\" ) )\n","    y_train = pickle.load( open(locstr + \"Data/\" + \"y_train.p\",\"rb\"))\n","    y_test = pickle.load( open(locstr + \"Data/\" + \"y_test.p\",\"rb\"))\n","    \n","except:\n","        \n","        print('exception in loading segmented data')\n","        X_train, X_test, y_train, y_test = train_test_split(NN_input,NN_output,test_size=0.3)\n","        \n","        pickle.dump(X_train, open( locstr + \"Data/\" + \"X_train.p\", \"wb\" ) )\n","        pickle.dump(X_test, open( locstr + \"Data/\" + \"X_test.p\", \"wb\" ) )\n","        pickle.dump(y_train, open( locstr + \"Data/\" + \"y_train.p\", \"wb\" ) )\n","        pickle.dump(y_test, open( locstr + \"Data/\" + \"y_test.p\", \"wb\" ) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qDV69_KY5TI","executionInfo":{"status":"ok","timestamp":1607679934454,"user_tz":300,"elapsed":13431,"user":{"displayName":"Jacob DiChiacchio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggsml0EbzAAuAM2dlM7pejj_NgNEY5eL2kWsPwm=s64","userId":"01066648639217777069"}},"outputId":"3bb63dd8-f160-47d4-aa0b-811ded51c2cf"},"source":["tf.print(\"X_train mean: \", tf.math.reduce_mean(X_train))\n","tf.print(\"X_train stdev: \", tf.math.reduce_std(X_train))\n","tf.print(\"y_train mean: \", tf.math.reduce_mean(y_train))\n","tf.print(\"y_train stdev: \", tf.math.reduce_std(y_train))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train mean:  1.1930075366304653\n","X_train stdev:  4.3379647876911962\n","y_train mean:  0.020408163265306121\n","y_train stdev:  0.066589406428670186\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"DFlJPrAdGb8A"},"source":["tf.keras.backend.set_floatx('float64')\n","\n","class BetaModel(tf.keras.Model):\n","    '''\n","    This model was an attempt to introduce a nondeterministic element into the network output. Each of the output bins is computed as a sample from an independent beta distribution parameterized by the network layers\n","    '''\n","    \n","    def __init__(self, num_bins):\n","        super(BetaModel, self).__init__()\n","        self.num_bins = num_bins\n","        # Training hyperparameters\n","        self.batch_size = 256\n","        self.learning_rate = .001\n","        self.optimizer = tf.keras.optimizers.Adam(learning_rate = self.learning_rate)\n","\n","        # Dense layer hyperparameters\n","        self.hidden_architecture = [100, 100, 100, 100]\n","        self.activation = tf.keras.layers.LeakyReLU(alpha=0.2)\n","        self.regularizer = {} #{'kernel_regularizer': keras.regularizers.l2(0.001), 'bias_regularizer': keras.regularizers.l2(0.001)}\n","\n","\n","        # Hidden layers\n","        self.hidden_layers = [keras.layers.Dense(size, activation = self.activation, **self.regularizer) for size in self.hidden_architecture]\n","        # Beta distribution parameters\n","        self.alpha = keras.layers.Dense(num_bins, activation= 'softplus', **self.regularizer)\n","        self.beta = keras.layers.Dense(num_bins, activation= 'softplus', **self.regularizer)\n","        # Softmax for final output\n","        self.softmax = keras.layers.Softmax()\n","\n","\n","\n","    def call(self, input):\n","        # Compute all hidden layer outputs\n","        layer_out = input\n","        for layer in self.hidden_layers:\n","            layer_out = layer(layer_out)\n","        # Compute distribution parameters\n","        alpha = self.alpha(layer_out)\n","        beta = self.beta(layer_out)\n","        # Initialize the the beta distributions\n","        dists = [tfp.distributions.Beta(alpha[:, bin], beta[:, bin], allow_nan_stats=False) for bin in range(self.num_bins)]\n","        # Sample each distribution and transpose to producean output tensor of shape (batch_size, num_bins)\n","        sampled = tf.transpose(tf.convert_to_tensor([dist.sample() for dist in dists]))\n","        # Softmax the sampled vector to ensure that the output is a well defined distribution\n","        return self.softmax(sampled)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"YSzl67NINA9c","outputId":"bb8a6253-436e-4d3a-a011-b2c8f3dee67d"},"source":["#Creating the Beta Distribution model\n","BETA = BetaModel(49)\n","\n","\"\"\"\n","Compiles all the data for training and testing the model. Creates a list of different loss functions to keep track of.\n","\"\"\"\n","losses = [\"mse\", \"kld\", \"mae\"]\n","BETA.compile(optimizer = BETA.optimizer, loss = losses[0], metrics = [\"kullback_leibler_divergence\",\"mean_squared_error\", \"mean_absolute_error\"])\n","\n","# Output name\n","outstr = locstr + 'Network Weights/BETA'\n","\n","if not include_last:\n","    outstr = outstr + '-nolast'        \n","\n","#Adds early stopping, if so desired\n","es = EarlyStopping(monitor='val_loss', verbose=1, patience=10);\n","\n","# Reduce learning rate on plateau\n","lradj = keras.callbacks.ReduceLROnPlateau()\n","\n","#Initializing necessary TensorBoard metrics for better metrics\n","tb_log = tf.keras.callbacks.TensorBoard(\n","    log_dir = locstr + \"logs\",\n","    histogram_freq = 5,\n","    write_graph = True,\n","    update_freq= 50,\n","    profile_batch=2,\n","    embeddings_freq=1)\n","\n","\"\"\"\n","Trains and tests the Beta Distribution network. Validation_data = data to be tested. Automatically trains and tests for 100 epochs\n","\"\"\"\n","history = BETA.fit(X_train,y_train, validation_data = (X_test,y_test), verbose = 1, batch_size = BETA.batch_size, epochs=100, callbacks = [lradj])\n","\n","#Saving the weights of the Beta model     \n","#BETA.save(outstr, save_format='tf')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1107/1107 [==============================] - 42s 38ms/step - loss: 0.0037 - kullback_leibler_divergence: 1.6542 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0315 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.6350 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0314\n","Epoch 2/100\n","1107/1107 [==============================] - 39s 35ms/step - loss: 0.0037 - kullback_leibler_divergence: 1.6281 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0314 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.6112 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0312\n","Epoch 3/100\n","1107/1107 [==============================] - 39s 35ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.6138 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0313 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.6091 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0312\n","Epoch 4/100\n","1107/1107 [==============================] - 39s 35ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.6063 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0312 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.6022 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0312\n","Epoch 5/100\n","1107/1107 [==============================] - 39s 35ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.6039 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0312 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.6073 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0313\n","Epoch 6/100\n","1107/1107 [==============================] - 40s 36ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.6030 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0312 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.6124 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0312\n","Epoch 7/100\n","1107/1107 [==============================] - 39s 36ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.6016 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0312 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5957 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 8/100\n","1107/1107 [==============================] - 40s 36ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5983 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0311 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.6075 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0312\n","Epoch 9/100\n","1107/1107 [==============================] - 40s 36ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.6056 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0312 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5959 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 10/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5995 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0312 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5928 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 11/100\n","1107/1107 [==============================] - 40s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5950 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0311 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5915 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 12/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5905 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0311 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5877 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 13/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5888 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0311 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5872 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 14/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5875 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0311 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5859 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 15/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5872 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0311 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5859 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 16/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5866 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0311 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5858 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 17/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5856 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0310 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5852 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0310\n","Epoch 18/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5856 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0310 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5848 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0310\n","Epoch 19/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5848 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0310 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5835 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0310\n","Epoch 20/100\n","1107/1107 [==============================] - 41s 37ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5864 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0311 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5852 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0311\n","Epoch 21/100\n","1107/1107 [==============================] - 42s 38ms/step - loss: 0.0036 - kullback_leibler_divergence: 1.5862 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0311 - val_loss: 0.0036 - val_kullback_leibler_divergence: 1.5833 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0310\n","Epoch 22/100\n"," 376/1107 [=========>....................] - ETA: 24s - loss: 0.0036 - kullback_leibler_divergence: 1.5834 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0310"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YrgmhQeSGb8A"},"source":["print(history.history)\n","pickle.dump(history.history, open( locstr + \"Data/\" + \"BETA-100x100x100x100x10-MSE-FAKE.p\", \"wb\" ))\n","plt.plot(log(history.history['loss']))\n","plt.plot(log(history.history['val_loss']))\n","np.min(history.history['val_loss'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8sp8Us6mGb8A"},"source":["#For assessing network performance, load a saved model.\n","model_name = 'Full-100x100x100x100x100-mse-FINAL.h5'\n","BETA = load_model(locstr + \"Network Weights/Horvat Checkpoints/\" + model_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9BBzcMWq1EfC"},"source":["eval = BETA.evaluate(X_test, return_dict = True)\n","for name in BETA.metrics_names:\n","    print(\"%s: %f\" % (name, eval[name]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k82sRNx6Gb8A"},"source":["# q = random.randint(0,y_test.shape[0])\n","# plt.semilogx(Rcent,y_test[q,:])\n","\n","# test_out = BETA.predict(np.expand_dims(X_test[q,:],axis=1).T).T\n","\n","# plt.semilogx(Rcent,test_out)\n","\n","# print('MAE value here is ' + str(sum(abs(np.subtract(np.expand_dims(y_test[q,:],axis=1),test_out)))))\n","\n","test_out = BETA.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvWTFn9KGb8B"},"source":["errmat = np.sum(np.abs((test_out - y_test)),axis=1)\n","errmat2 = np.mean((test_out - y_test)**2,axis=1)\n","testE = np.sum(X_test[:,:25]*dFreq.T,axis=1)\n","testH = X_test[:,-1]\n","\n","print(errmat.shape)\n","print(testE.shape)\n","print(testH.shape)\n","\n","print('SAE is: ' + str(np.nanmean(errmat)))\n","print(\">10% SAE is: \" + str(np.sum(errmat > 0.1)/len(X_test)))\n","print('MSE is: ' + str(np.nanmean(errmat2)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SlbZeOUSqwAu"},"source":["feed_forward_network = load_model(locstr + \"Network Weights/\" + \"Full-100x100x100x100x100-mse-FINAL_2.h5\")"],"execution_count":null,"outputs":[]}]}